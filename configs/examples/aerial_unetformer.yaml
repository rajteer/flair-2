# ============================================================================
# Aerial Segmentation Pipeline — UNetFormer (swsl_resnet18)
# ============================================================================
# This config trains a UNetFormer model — a custom UNet-like architecture
# with Global-Local Attention in the decoder. Uses a ResNet-18 backbone
# from timm with semi-weakly supervised ImageNet weights (swsl).
#
# UNetFormer is particularly effective for remote sensing segmentation
# due to its efficient attention mechanism over local windows.
#
# Reference: Wang et al., "UNetFormer: A UNet-like transformer for
#            efficient semantic segmentation of remote sensing images"
#
# Usage:
#   python -m src.pipeline.pipeline -c configs/examples/aerial_unetformer.yaml
# ============================================================================

data:
  train:
    images: ./data/flair_2_aerial_train
    masks:  ./data/flair_2_labels_train
    sentinel: ./data/flair_2_sen_train
  val:
    images: ./data/flair_2_aerial_test
    masks:  ./data/flair_2_labels_test
    sentinel: ./data/flair_2_sen_test
  test:
    images: ./data/flair_2_aerial_test
    masks:  ./data/flair_2_labels_test
    sentinel: ./data/flair_2_sen_test

  centroids_path: ./data/flair-2_centroids_sp_to_patch.json
  dataset_version: split_40
  num_classes: 13
  batch_size: 8
  num_workers: 4
  pin_memory: true
  selected_channels: [0, 1, 2, 3, 4]

  normalization:
    enabled: true
    mean: [0.485, 0.456, 0.406, 0.409878, 0.068752]
    std:  [0.229, 0.224, 0.225, 0.155107, 0.118672]
    scale_to_unit: [true, true, true, true, false]
    elevation_range: [0.0, 255.0]
    elevation_channel_index: 4

  other_class_index: 12
  use_sentinel: false

  data_augmentation:
    apply_augmentations: true
    clamp: true
    augmentations:
      hflip:
        prob: 0.5
      vflip:
        prob: 0.5
      rotation:
        prob: 0.5
        angles: [0, 90, 180, 270]
      contrast:
        prob: 0.5
        range: [0.8, 1.2]
      brightness:
        prob: 0.5
        range: [0.8, 1.2]
      elevation_shift:
        prob: 0.5
        range: [-10.0, 10.0]
      elevation_scale:
        prob: 0.5
        range: [0.9, 1.1]
      elevation_dropout:
        prob: 0.1
        p: 0.1
      chessmix:
        prob: 0.5
        grid_sizes: [4]
        apply_transforms: true
        ignore_index: 12
        class_counts: []

mlflow:
  name: aerial-segmentation
  run_name: unetformer_resnet18
  tracking_uri: null
  note: "UNetFormer with swsl_resnet18 backbone"
  dagshub:
    enabled: false
    repo_owner: your-username
    repo_name: flair-2
    branch: null

model:
  # UNetFormer is a custom model — it uses model_type to select the
  # architecture and model_config for model-specific parameters.
  model_type: UNetFormer

  # encoder_name is used for the timm backbone inside UNetFormer.
  # Options: swsl_resnet18, resnet50, convnext_tiny, etc.
  encoder_name: swsl_resnet18
  encoder_weights: imagenet
  activation: null
  dynamic_img_size: false

  # UNetFormer-specific hyperparameters (passed via model_config)
  model_config:
    decode_channels: 64          # Decoder hidden dimension
    dropout: 0.1                 # Dropout rate in decoder
    window_size: 8               # Local attention window size
    use_aux_head: false          # Enable auxiliary head for deep supervision
    # backbone_name is automatically inferred from encoder_name
    # but can be overridden here:
    # backbone_name: swsl_resnet18

training:
  device: cuda
  optimizer:
    type: AdamW
    learning_rate: 0.0001
    betas: [0.9, 0.95]
    weight_decay: 0.00001
  lr_scheduler:
    type: ReduceLROnPlateau
    args:
      mode: min
      factor: 0.5
      patience: 3
      threshold: 0.0001
  epochs: 50
  early_stopping_patience: 5
  early_stopping_criterion: loss
  loss_function:
    type: LovaszLoss
    args:
      mode: multiclass

experiment:
  seed: 42
  deterministic: true

evaluation:
  log_confusion_matrix: true
  log_comparison: true
  log_sample_ids:
    - "006512"
    - "006975"

visualization:
  language: en
  labels:
    ground_truth: Ground Truth
    prediction: Prediction
    predicted_class: Predicted Class
    actual_class: Actual Class
    confusion_matrix_title: Confusion Matrix
