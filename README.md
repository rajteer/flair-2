# FLAIR-2 Segmentation Pipeline

> A modular training and evaluation framework for semantic segmentation of aerial and Sentinel-2 satellite imagery, built on the [FLAIR-2 dataset](https://ignf.github.io/FLAIR/).

Developed as part of a master's thesis on multimodal fusion of high-resolution aerial imagery and Sentinel-2 time series for land cover mapping.

---

## Key Features

- **7+ model architectures** ‚Äî SMP-based (i.e. Unet, DeepLabV3+, Segformer, FPN), UNetFormer, RS3Mamba, Samba, TSViT, UTAE++
- **3 training pipelines** ‚Äî aerial-only, Sentinel-2 temporal, and multimodal late fusion
- **Hyperparameter optimization** ‚Äî Optuna-powered search with MLflow integration
- **Experiment tracking** ‚Äî MLflow logging with confusion matrices, prediction visualizations, and config snapshots
- **Data augmentation** ‚Äî Flips, rotations, contrast/brightness, elevation perturbations, and ChessMix [[arXiv:2108.11535]](https://arxiv.org/abs/2108.11535) 
- **Fully configurable** ‚Äî YAML-driven with per-experiment configuration

---

## Repository Structure

```
flair-2/
‚îú‚îÄ‚îÄ configs/                    # Configuration files
‚îÇ   ‚îú‚îÄ‚îÄ examples/               # Documented example configs for every pipeline
‚îÇ   ‚îú‚îÄ‚îÄ config.yaml             # Default aerial pipeline config
‚îÇ   ‚îú‚îÄ‚îÄ config_multimodal.yaml  # Multimodal late fusion config
‚îÇ   ‚îú‚îÄ‚îÄ config_sentinel_*.yaml  # Sentinel-only pipeline configs
‚îÇ   ‚îî‚îÄ‚îÄ optimization*.yaml     # Optuna hyperparameter search configs
‚îú‚îÄ‚îÄ scripts/                    # Utility scripts
‚îÇ   ‚îú‚îÄ‚îÄ run_train_eval.sh       # Launcher script
‚îÇ   ‚îú‚îÄ‚îÄ benchmark_inference.py  # Inference speed benchmarking
‚îÇ   ‚îú‚îÄ‚îÄ compute_channel_stats.py # NIR/elevation normalization stats
‚îÇ   ‚îú‚îÄ‚îÄ compute_class_weights.py # Class frequency weights
‚îÇ   ‚îî‚îÄ‚îÄ compute_sentinel_stats.py # Sentinel-2 band statistics
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pre_processing/     # Dataset classes and augmentation
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ flair_dataset.py           # Aerial (+optional Sentinel) dataset
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ flair_sentinel_dataset.py  # Sentinel-2 only dataset
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ flair_multimodal_dataset.py # Multimodal dataset
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data_augmentation.py       # Augmentation transforms
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chessmix.py                # ChessMix augmentation
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ sentinel_utils.py          # Sentinel-2 data loading utilities
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ dataset_utils.py    # Collate functions and path utilities
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ architectures/      # Model architectures
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ unetformer.py       # UNetFormer architecture
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tsvit.py            # Temporal-Spatial Vision Transformer
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tsvit_lookup.py     # TSViT variant with lookup embeddings
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ rs3mamba.py         # RS3Mamba (SSM-based segmentation)
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ utae_pp.py          # U-TAE++ (modernized U-TAE)
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ multimodal_fusion.py # Late fusion model
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ encoders/           # Encoder backbones
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ samba_encoder.py    # Samba encoder backbone
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ vssm_encoder.py     # Visual State Space Model encoder
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ common_blocks.py    # Shared building blocks
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ model_builder.py    # Unified model/optimizer/loss factory
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ utils.py            # Model utility functions
‚îÇ   ‚îú‚îÄ‚îÄ training/               # Training and evaluation
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train.py            # Training and validation loops
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ validation.py       # Evaluation metrics computation
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ losses.py           # Custom loss functions
‚îÇ   ‚îú‚îÄ‚îÄ pipeline/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pipeline.py              # Aerial training/eval pipeline
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sentinel_pipeline.py     # Sentinel-2 training/eval pipeline
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ multimodal_pipeline.py   # Multimodal fusion pipeline
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ optimization.py          # Optuna HPO for aerial models
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ sentinel_optimization.py # Optuna HPO for Sentinel models
‚îÇ   ‚îú‚îÄ‚îÄ utils/                   # MLflow, logging, reproducibility
‚îÇ   ‚îî‚îÄ‚îÄ visualization/          # Prediction mosaics and plots
‚îî‚îÄ‚îÄ tests/                      # Unit tests
```

---

## üèóÔ∏è Supported Models

| Model | Type | Pipeline | Description |
|-------|------|----------|-------------|
| **Unet** | SMP | Aerial | Classic U-Net with configurable encoder |
| **DeepLabV3+** | SMP | Aerial | Atrous spatial pyramid pooling decoder |
| **Segformer** | SMP | Aerial | Transformer-based segmentation |
| **FPN** | SMP | Aerial | Feature Pyramid Network |
| **UNetFormer** | Custom | Aerial | UNet-like Transformer with Global-Local Attention |
| **RS3Mamba** | Custom | Aerial | State Space Model for remote sensing |
| **Samba** | Custom | Aerial | Samba encoder with UNetFormer decoder |
| **TSViT** | Custom | Sentinel | Temporal-Spatial Vision Transformer |
| **UTAE++** | Custom | Sentinel | Modernized U-TAE with ConvNeXt blocks |
| **MultimodalLateFusion** | Custom | Multimodal | Late fusion of aerial + Sentinel models |

---

## üìä Dataset

This pipeline is designed for the [FLAIR-2 dataset](https://ignf.github.io/FLAIR/) ‚Äî a large-scale benchmark for land cover segmentation in France.

### Data Modalities

| Modality | Resolution | Channels | Description |
|----------|-----------|----------|-------------|
| **Aerial** | 0.2 m/px | 5 (R, G, B, NIR, Elevation) | High-resolution ortho-imagery |
| **Sentinel-2** | 10 m/px | 10 spectral bands | Multispectral time series (variable length) |

### Expected Directory Layout

```
data/
‚îú‚îÄ‚îÄ flair_2_aerial_train/       # Training aerial images (IMG_*.tif)
‚îú‚îÄ‚îÄ flair_2_aerial_test/        # Test aerial images
‚îú‚îÄ‚îÄ flair_2_labels_train/       # Training masks (MSK_*.tif)
‚îú‚îÄ‚îÄ flair_2_labels_test/        # Test masks
‚îú‚îÄ‚îÄ flair_2_sen_train/          # Training Sentinel-2 super-patches
‚îú‚îÄ‚îÄ flair_2_sen_test/           # Test Sentinel-2 super-patches
‚îî‚îÄ‚îÄ flair-2_centroids_sp_to_patch.json  # Aerial ‚Üí Sentinel coordinate mapping
```
---

## Installation

**Prerequisites**: Python ‚â• 3.11, CUDA-capable GPU recommended.

```bash
# Clone the repository
git clone https://github.com/rajteer/flair-2.git
cd flair-2

# Install with uv (recommended)
uv sync

# Or with pip
pip install -e .
```

---

## Quick Start

### 1. Aerial Image Segmentation

Train a segmentation model on aerial imagery:

```bash
# Using the launcher script (default: configs/config.yaml)
./scripts/run_train_eval.sh

# With a specific config
./scripts/run_train_eval.sh configs/examples/aerial_unetformer.yaml

# Direct Python invocation
python -m src.pipeline.pipeline -c configs/examples/aerial_segformer.yaml
```

### 2. Sentinel-2 Temporal Segmentation

Train a temporal model on Sentinel-2 time series:

```bash
python -m src.pipeline.sentinel_pipeline -c configs/examples/sentinel_tsvit.yaml
```

### 3. Multimodal Late Fusion

Combine pre-trained aerial and Sentinel models:

```bash
python -m src.pipeline.multimodal_pipeline -c configs/examples/multimodal_late_fusion.yaml
```

> **Note**: Multimodal fusion requires pre-trained checkpoints for both the aerial and Sentinel models. Set `model.aerial_checkpoint` and `model.sentinel_checkpoint` in the config.

### 4. Hyperparameter Optimization

Run Optuna-powered hyperparameter search:

```bash
# Aerial models
python -m src.pipeline.optimization \
    -c configs/examples/aerial_segformer.yaml \
    -o configs/examples/optimization_aerial.yaml

# Sentinel models
python -m src.pipeline.sentinel_optimization \
    -c configs/examples/sentinel_tsvit.yaml \
    -o configs/examples/optimization_sentinel.yaml
```

---

## Configuration Reference

All behavior is controlled through YAML configuration files. See `configs/examples/` for fully documented examples.

| Section | Description |
|---------|-------------|
| `data` | Dataset paths, batch size, channels, normalization, augmentation, Sentinel options |
| `model` | Architecture type, encoder, weights, model-specific hyperparameters |
| `training` | Optimizer, LR scheduler, epochs, early stopping, loss function |
| `experiment` | Random seed, deterministic mode |
| `mlflow` | Experiment name, run name, tracking URI, DagsHub integration |
| `evaluation` | Confusion matrix logging, sample comparison visualizations |
| `visualization` | Language (`en`/`pl`), display labels |

### Loss Functions

| Loss | Config Key | Description |
|------|-----------|-------------|
| CrossEntropyLoss | `CrossEntropyLoss` | Standard CE with optional `ignore_index` |
| LovaszLoss | `LovaszLoss` | Lov√°sz-Softmax for IoU optimization |
| CombinedDiceFocalLoss | `CombinedDiceFocalLoss` | Weighted Dice + Focal with class weights |
| WeightedCrossEntropyDiceLoss | `WeightedCrossEntropyDiceLoss` | Weighted CE + Dice |

### LR Schedulers

| Scheduler | Config Key |
|-----------|-----------|
| ReduceLROnPlateau | `ReduceLROnPlateau` |
| OneCycleLR | `OneCycleLR` |
| CosineAnnealingWarmRestarts | `CosineAnnealingWarmRestarts` |
| StepLR | `StepLR` |

---

## Experiment Tracking

Experiments are tracked with **MLflow**. Optionally, [DagsHub](https://dagshub.com/) can be used for remote tracking.

### What gets logged

- Training/validation loss and mIoU per epoch
- Model parameters count (total and trainable)
- Model FLOPs (per sample)
- Resolved configuration snapshot (`config_resolved.json`)
- Best model checkpoint (`best_model.pt`)
- Confusion matrix (as artifact)
- Prediction comparison mosaics for selected samples
- Learning rate and optimizer state

### Log files

Each pipeline run creates a timestamped log file in the working directory:
```
pipeline_20260221_120000_ExperimentName.log
```

---

## Utility Scripts

| Script | Description | Usage |
|--------|-------------|-------|
| `compute_channel_stats.py` | Compute NIR/elevation normalization statistics | `python scripts/compute_channel_stats.py --images-dir data/flair_2_aerial_train` |
| `compute_class_weights.py` | Calculate class frequency weights for loss balancing | `python scripts/compute_class_weights.py --config configs/config.yaml` |
| `compute_sentinel_stats.py` | Compute Sentinel-2 band statistics | `python scripts/compute_sentinel_stats.py --data-dir data/flair_2_sen_train` |
| `benchmark_inference.py` | Benchmark model inference speed | `python scripts/benchmark_inference.py --config configs/config.yaml --checkpoint path/to/model.pt` |

---

## Reproducibility

Reproducibility is controlled via the `experiment` section:

```yaml
experiment:
  seed: 42            # Random seed for all RNGs (Python, NumPy, PyTorch, CUDA)
  deterministic: true  # Enable PyTorch deterministic algorithms
```

All experiments in this project were conducted with `seed: 42`. All random generators (data loaders, augmentation, model initialization) are seeded from `experiment.seed`.

---

## Testing

Run the test suite:

```bash
# With uv
uv run pytest tests/ -v

# With pip
pytest tests/ -v
```